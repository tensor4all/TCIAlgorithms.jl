{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bethe-Salpeter equation in QTCI representation with patches (TODO: Title OK?, QTCI or QTT?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bethe-Salpeter equation\n",
    "\n",
    "Our objective in this work is computing the Bethe-Salpeter equation (BSE), which relates the full vertex $F^r$, the bare susceptibility ${\\Chi_0}^r$ and the channel-irreducible vertex $\\Gamma^r$\n",
    "$$\n",
    "    F^r_{\\nu\\nu'\\omega} = \\Gamma^r_{\\nu\\nu'\\omega} + \\frac{1}{\\beta^2}\\sum_{\\nu''\\nu'''} F^r_{\\nu\\nu''\\omega} {\\Chi_0}^r_{\\nu''\\nu'''\\omega} \\Gamma^r_{\\nu'''\\nu'\\omega}.\n",
    "$$\n",
    "The sum term is equal to the channel-reducible vertex $\\Phi^r \\equiv F^r_{\\nu\\nu'\\omega} - \\Gamma^r_{\\nu\\nu'\\omega}$.\n",
    "Here, $r$ denotes one of four (density $r=d$, magnetic $r=m$, singlet $r=s$, triplet $r=t$) channels, $\\nu$ (and its primed variants) a fermionic Matsubara frequency (of the form $(2n+1)\\pi/\\beta$ for some integer $n$) and $\\omega$ a bosonic Matsubara frequency (of the form $2m\\pi/\\beta$ for some integer $m$).\n",
    "The sums are performed over all fermionic frequencies and $\\beta = 1/T$ is inverse temperature.\n",
    "\n",
    "If we chose to straightforwardly represent our quantities by sampling them in a box centered on the origin, the BSE would be easy to implement: For each bosonic frequency, two matrix-matrix multiplications would suffice.\n",
    "But as this strategy sooner rather than later hits a wall in terms of computing power and memory requirements when approaching lower temperatures, where a larger frequency box is required to yield the same accuracy target in the BSE, people have been looking for alternative solutions for some time. (TODO: sources)\n",
    "\n",
    "## Quantics tensor trains\n",
    "\n",
    "In the present work, we utilize a quantics tensor train (QTT) representation [@Shinaoka2023].\n",
    "A function of a single Matsubara frequency $f_\\nu$ can be approximately represented by its values on a $2^R$-frequency mesh $\\nu \\in \\{\\pi/\\beta, 3\\pi/\\beta, \\ldots, (2^{R+1} - 1)\\pi/\\beta\\}$ (in practice, the frequency box is usually centered on the origin) where $R \\in \\mathbb{N}$ controls the accuracy of the representation.\n",
    "Each such $\\nu$ can be written as\n",
    "$$\n",
    "    \\nu = \\left(\\nu_1 2^R + \\nu_2 2^{R-1} + \\ldots + \\nu_R + 1\\right)\\pi/\\beta\n",
    "$$\n",
    "where the $\\nu_r \\in \\{0, 1\\}$ are binary variables.\n",
    "Thus $f$ can be viewed as an order-$R$ tensor,\n",
    "$$\n",
    "    f_\\nu = f_{\\nu_1\\nu_2\\ldots\\nu_R}\n",
    "$$\n",
    "which then allows us to perform SVD and convert it into a tensor train (also known as multi-particle state or MPS)\n",
    "$$\n",
    "    f_{\\nu_1\\nu_2\\ldots\\nu_R} \\approx \\sum_{\\alpha_1=1}^{D_1} \\cdots \\sum_{\\alpha_{R-1}=1}^{D_{R-1}} f^{(1)}_{\\nu_1,1\\alpha_1} f^{(2)}_{\\nu_2,\\alpha_1\\alpha_2} \\cdots f^{(R)}_{\\nu_R,\\alpha_{R-1}1}. \n",
    "$$\n",
    "Here, $f^{(r)}_{\\nu_r,\\alpha_{r-1}\\alpha_{r}}$ is a $2 \\times D_{r-1} \\times D_r$ tensor and $D_r$ is the bond dimension between two neighboring tensors.\n",
    "We call $\\alpha_r$ the bond (or internal) indices, $\\nu_r$ the local (or external) indices and $D = \\max_r D_r$ the tensor train's bond dimension.\n",
    "If it is high enough, $D \\sim 2^R$, the tensor is represented exactly, but to compress the original function, we can truncate the tensor and throw away unimportant information.\n",
    "We will not go into the details of how to find the tensor train representation here, but suffice it to say we employ Tensor cross interpolation (TCI) [@Ritter2024].\n",
    "\n",
    "### Multi-particle operators\n",
    "\n",
    "A very similar concept is that of an multi-particle operator (MPO), which consists of order 4 tensors and has two external indices per tensor.\n",
    "As the name implies, an MPO can be multiplied onto an MPS (or another MPO), being analogous to a matrix if MPSs are viewed as analogous to vectors:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    (A \\cdot f)_{\\nu_1\\ldots\\nu_R} &= \\sum_{\\nu_1',\\ldots,\\nu_R'} A^{(1),\\nu_1'}_{\\nu_1} \\cdot \\ldots \\cdot A^{(R),\\nu_R'}_{\\nu_R} f^{(1)}_{\\nu_1'} \\cdot \\ldots \\cdot f^{(R)}_{\\nu_R'} \\\\\n",
    "    &= \\sum_{\\nu_1',\\ldots,\\nu_R'} \\sum_{\\alpha_{A,1},\\ldots,\\alpha_{A,R}} \\sum_{\\alpha_{f,1},\\ldots,\\alpha_{f,R}} A^{(1),\\nu_1'}_{\\nu_1,1\\alpha_{A,1}} f^{(1)}_{\\nu_1',1\\alpha_{f,1}} \\cdots A^{(R),\\nu_R'}_{\\nu_R,\\alpha_{A,R}1} f^{(R)}_{\\nu_R',\\alpha_{f,R}1}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Multiple variables\n",
    "\n",
    "To form the MPS of a multivariate function $f_{\\nu\\nu'}$, we have two choices:\n",
    "\n",
    "- Interleaved representation: $2R$ tensors of dimension $2 \\times D_{r-1} \\times D_r$.\n",
    "    $$\n",
    "        f_{\\nu\\nu'} \\approx \\sum_{\\alpha_1=1}^{D_1} \\cdots \\sum_{\\alpha_{2R-1}=1}^{D_{2R-1}} f^{(1)}_{\\nu_1,1\\alpha_1} f^{(2)}_{\\nu_1',\\alpha_1\\alpha_2} f^{(3)}_{\\nu_2,\\alpha_2\\alpha_3} f^{(4)}_{\\nu_2',\\alpha_3\\alpha_4} \\cdots f^{(2R-1)}_{\\nu_R,\\alpha_{2R-2}\\alpha_{2R-1}} f^{(2R)}_{\\nu_R',\\alpha_{2R-1}1}\n",
    "    $$\n",
    "- Fused representation: $R$ tensors of dimension $4 \\times D_{r-1} \\times D_r$.\n",
    "    $$\n",
    "        f_{\\nu\\nu'} \\approx \\sum_{\\alpha_1=1}^{D_1} \\cdots \\sum_{\\alpha_{R-1}=1}^{D_{R-1}} f^{(1)}_{(\\nu_1,\\nu_1'),1\\alpha_1} f^{(2)}_{(\\nu_2,\\nu_2'),\\alpha_1\\alpha_2} \\cdots f^{(R)}_{(\\nu_R,\\nu_R'),\\alpha_{R-1}1}\n",
    "    $$\n",
    "\n",
    "In the following, we will work in the fused representation.\n",
    "\n",
    "### Multiplication (contraction) of MPSs\n",
    "\n",
    "For clarity, we will use $i$, $j$ and $k$ in this section instead of $\\nu$, $\\nu'$ and $\\nu''$.\n",
    "To compute\n",
    "$$\n",
    "    h_{ij} = \\sum_k f_{ik} g_{kj},\n",
    "$$\n",
    "we introduce an auxiliary MPO $\\hat{f}$ such that\n",
    "$$\n",
    "    h_{ij} = \\sum_{kl} \\hat{f}^{kl}_{ij} g_{kl}\n",
    "$$\n",
    "which is given by\n",
    "$$\n",
    "    \\hat{f}^{kl}_{ij} = \\sum_{\\alpha_1,\\ldots,\\alpha_{R_1}} \\hat{f}^{(1),(k_1, l_1)}_{(i_1, j_1),1\\alpha_1} \\hat{f}^{(2),(k_2, l_2)}_{(i_2, j_2),\\alpha_1\\alpha_2} \\cdots \\hat{f}^{(R),(k_R, l_R)}_{(i_R, j_R),\\alpha_{R-1}1}\n",
    "$$\n",
    "with\n",
    "$$\n",
    "    \\hat{f}^{(r),(k_r, l_r)}_{(i_r, j_r),\\alpha_{r-1}\\alpha_r} = f^{(r)}_{(k_r, i_r),\\alpha_{r-1}\\alpha_r} \\delta_{l_rj_r}.\n",
    "$$\n",
    "This enables us to use efficient MPO-MPS multiplication implementations.\n",
    "\n",
    "### Adaptive patching\n",
    "\n",
    "To more efficiently compress the information we handle, we choose a strategy of adaptive patching by setting an upper bound $D_\\mathrm{max}$ to the bond dimension $D$.\n",
    "For illustration, picture a function $f(x, y)$ on a square domain $[0, 1]^2$.\n",
    "We generate via TCI an MPS approximating $f$ on a $R \\times R$ mesh with a certain measure of precision, discarding rows/columns of its tensors such that the result is equal to $f$ to within a given tolerance.\n",
    "Now, if the MPS's bond dimension exceeds $D_\\mathrm{max}$, we divide the domain into 4 smaller squares (or \"patches\") and construct an MPS on each with $R' \\times R'$ where $R' = R - 1$, reusing the exact same interpolation points as the original domain.\n",
    "We repeat this process, recursively subdividing our domain until the bond dimensions of all MPSs is smaller than or equal to $D_\\mathrm{max}$.\n",
    "\n",
    "The idea here is that in this way, we resolve more finely regions of the domain where $f$'s complexity is higher and are able to limit the bond dimension in areas of lower complexity, saving memory.\n",
    "Of course, on the other hand, now multiplication becomes more involved.\n",
    "Although they live on the same domain, multiplier and multiplicand are in general going to consist of different patches, so when multiplying we iterate over both sets of patches and test for overlapping patches which can then be multiplied as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration\n",
    "\n",
    "We would now like to demonstrate the discussed techniques.\n",
    "To this end, we choose the Hubbard Atom (############## TODO: intro Hubbard model?), where exact expressions for all quantities are known [@Thunström2018] and implemented in the package `HubbardAtoms.jl`.\n",
    "\n",
    "A host of Julia packages is necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import QuanticsGrids as QG     # utilities for handling quantics representations\n",
    "import TCIAlgorithms as TCIA   # implementation of patching\n",
    "using HubbardAtoms             # exact results for the Hubbard atom\n",
    "using SparseIR                 # provides the MatsubaraFreq types used in the HubbardAtoms package\n",
    "using Quantics                 # high-level API for performing operations in QTT\n",
    "using ITensors                 # efficient tensor computations and tensor network calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use `QuanticsGrids.jl` to create a grid in the shape of a $R \\times R \\times R$ cube almost centered on the origin of \"fermionic × fermionic × bosonic\" Matsubara frequency space.\n",
    "\"Almost\", because by construction the grid consists of an even number of points ($2^R$) in each direction and bosonic Matsubara frequencies are even, so a grid centered on the origin would include an odd number of frequencies.\n",
    "This is something that will not affect our calculations in this example however, because we never sum over the bosonic axis.\n",
    "If we wanted to do that -- e.g. in implementing the Schwinger-Dyson equation -- special care would need to be taken.\n",
    "\n",
    "Later, interoperation between `TCIAlgorithms.jl` and `ITensors.jl` will be necessary, so we prepare the relevant `ITensors.Index` objects.\n",
    "`zip`ing the indiviual axes' indices together corresponds to creating the indices in the fused representation introduce above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "function setup(R=4)\n",
    "    N = 2^R\n",
    "    grid = QG.InherentDiscreteGrid{3}(R, (-N + 1, -N + 1, -N); step=2, unfoldingscheme=:fused)\n",
    "\n",
    "    sitesν = [Index(2, \"ν=$r\") for r in 1:R]\n",
    "    sitesν´ = [Index(2, \"ν´=$r\") for r in 1:R]\n",
    "    sitesω = [Index(2, \"ω=$r\") for r in 1:R]\n",
    "    sitesfused = collect.(zip(sitesν, sitesν´, sitesω))\n",
    "    sites = (; sitesν, sitesν´, sitesω, sitesfused)\n",
    "\n",
    "    return grid, sites\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use `HubbardAtoms.jl` to introduce the exact vertex functions $F$, $\\Chi^0$ and $\\Gamma$ and wrap them with `QuanticsGrids.quanticsfunction` to take a list of binary indices as input instead of the plain Matsubara frequencies.\n",
    "Here, we also absorb the factor of $1 / \\beta^2$ that appears in the BSE into the bare susceptibility for later convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "function makeverts(U, beta, ch, grid)\n",
    "    model = HubbardAtom(U, beta)\n",
    "\n",
    "    fq_full(x, y, z) = real(full_vertex(ch, model, (FermionicFreq(x), FermionicFreq(y), BosonicFreq(z))))\n",
    "    fq_chi0(x, y, z) = 1 / beta^2 * real(chi0(ch, model, (FermionicFreq(x), FermionicFreq(y), BosonicFreq(z))))\n",
    "    fq_gamma(x, y, z) = real(gamma(ch, model, (FermionicFreq(x), FermionicFreq(y), BosonicFreq(z))))\n",
    "    plainfuncs = (; fq_full, fq_chi0, fq_gamma)\n",
    "\n",
    "    fI_full = QG.quanticsfunction(Float64, grid, fq_full)\n",
    "    fI_chi0 = QG.quanticsfunction(Float64, grid, fq_chi0)\n",
    "    fI_gamma = QG.quanticsfunction(Float64, grid, fq_gamma)\n",
    "    quanticsfuncs = (; fI_full, fI_chi0, fI_gamma)\n",
    "\n",
    "    return plainfuncs, quanticsfuncs\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we work in 3 dimensions in the fused representation, the local index' dimension is $2^3 = 8$ for each tensor in the MPS, i.e. `localdims == fill(8, R) == [8, 8, …, 8]`.\n",
    "The function `makeprojectable` creates a `ProjectableEvaluatorAdapter`, which represents an object that can be projected on a subset of indices.\n",
    "For this purpose, it contains a `Projector` which can be thought of as restricting the function's support to a subset of its domain, giving zero elsewhere.\n",
    "A worked example will clarify this idea. For illustration, let's assume quantics, i.e. the tensors represent functions:\n",
    "\n",
    "```julia\n",
    "localdims = [2, 2, 2]                                   # We work in one dimension with R = 3,\n",
    "                                                        # i.e. a sequence of 2^R = 8 points on a line.\n",
    "                                                        # Thinking of the interval [0.0, 1.0], the\n",
    "                                                        # point 0.0 would be represented by [1, 1, 1];\n",
    "                                                        # 0.25 would be [1, 2, 1] and 0.875 [2, 2, 2].\n",
    "sitedims = [[x] for x in localdims]\n",
    "projector = TCIA.Projector([[1], [0], [0]], sitedims)   # This projector restricts the function's domain\n",
    "                                                        # to the first half of the interval, i.e. [0.0, 0.5).\n",
    "                                                        # If we had used e.g. [[1], [2], [0]], only the\n",
    "                                                        # second quarter of points would give nonzero\n",
    "                                                        # results on evaluation. So a 0 means no restriction.\n",
    "\n",
    "simple_evaluator(x) = sum(x)\n",
    "projectable_evaluator = TCIA.makeprojectable(Float64, simple_evaluator, localdims)\n",
    "projected_evaluator = TCIA.project(projectable_evaluator, projector)\n",
    "\n",
    "@show projected_evaluator([1, 1, 1])                    # Evaluate on [1, 1, 1] = 0.0\n",
    "@show projected_evaluator([2, 1, 1])                    # Evaluate on [2, 1, 1] = 0.5\n",
    "@show projected_evaluator([2, 2, 1])                    # Evaluate on [2, 2, 1] = 0.75\n",
    "```\n",
    "\n",
    "Result:\n",
    "```julia\n",
    "projected_evaluator([1, 1, 1]) = 3.0\n",
    "projected_evaluator([2, 1, 1]) = 0.0\n",
    "projected_evaluator([2, 2, 1]) = 0.0\n",
    "```\n",
    "Note: As the name implies, `makeprojectable`'s result is projectable, but not yet projected.\n",
    "\n",
    "In the next step, the so created projectable evaluators are now adaptively TCIed into patched MPSs by way of `adaptiveinterpolate` (the algorithm is sketched above) creating a `ProjContainer{ProjTensorTrain}` (which happens to share its supertype `ProjectableEvaluator` with `ProjectableEvaluatorAdapter`).\n",
    "Principally this contains an array of `ProjTensorTrain`s -- each of which represents a tensor train projected onto a subregion of the domain -- that are allowed to overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "function interpolateverts(quanticsfuncs, grid, maxbonddim, sites)\n",
    "    (; fI_full, fI_chi0, fI_gamma) = quanticsfuncs\n",
    "    \n",
    "    localdims = dim.(sites.sitesfused)\n",
    "    projectable_full = TCIA.makeprojectable(Float64, fI_full, localdims)\n",
    "    projectable_chi0 = TCIA.makeprojectable(Float64, fI_chi0, localdims)\n",
    "    projectable_gamma = TCIA.makeprojectable(Float64, fI_gamma, localdims)\n",
    "    \n",
    "    initialpivots = [QG.origcoord_to_quantics(grid, 0)] # approximate center of grid\n",
    "    full_patches = TCIA.adaptiveinterpolate(projectable_full; maxbonddim, initialpivots)\n",
    "    chi0_patches = TCIA.adaptiveinterpolate(projectable_chi0; maxbonddim, initialpivots)\n",
    "    gamma_patches = TCIA.adaptiveinterpolate(projectable_gamma; maxbonddim, initialpivots)\n",
    "    \n",
    "    sitedims = [dim.(s) for s in sites.sitesfused]\n",
    "    full_patches = reshape(full_patches, sitedims)\n",
    "    chi0_patches = reshape(chi0_patches, sitedims)\n",
    "    gamma_patches = reshape(gamma_patches, sitedims)\n",
    "\n",
    "    patchesfuncs = (; full_patches, chi0_patches, gamma_patches)\n",
    "\n",
    "    return patchesfuncs\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed above, to contract two MPSs, we turn the first one into an MPO.\n",
    "For technical reasons, This requires a couple of steps:\n",
    "1. Convert `ProjContainer{ProjTensorTrain}` into `ProjMPSContainer`, essentially a `Vector{ProjMPS}`. `ProjMPS` is backed by `ITensors.MPS` which supports tensors of heterogeneous order within a single tensor train. The following steps are performed for each tensor train/patch.\n",
    "2. Separate off the $\\omega$ indices into their own tensors:\n",
    "    $$\n",
    "        F_{\\nu\\nu'\\omega} = \\sum_{\\alpha_1,\\ldots,\\alpha_{R-1}} F^{(1)}_{(\\nu_1,\\nu_1',\\omega_1),1\\alpha_1} \\cdots F^{(R)}_{(\\nu_R,\\nu_R',\\omega_R),\\alpha_{R-1}1} \\longrightarrow \\sum_{\\alpha_1,\\ldots,\\alpha_{2R-1}} F^{(1)}_{(\\nu_1,\\nu_1'),1\\alpha_1} F^{(2)}_{\\omega_1,\\alpha_1\\alpha_2} \\cdots F^{(2R-1)}_{(\\nu_R,\\nu_R'),\\alpha_{2R-2}\\alpha_{2R-1}} F^{(2R)}_{\\omega_R,\\alpha_{2R-1}1}\n",
    "    $$\n",
    "3. Make the new \"$\\omega$-tensors\" diagonal by adding an additional $\\omega'$ index, i.e.\n",
    "   $$\n",
    "       F^{(r)}_{\\omega_r,\\alpha_{r-1}\\alpha_r} \\longrightarrow F^{(r)}_{(\\omega_r,\\omega_r'),\\alpha_{r-1}\\alpha_r} = F^{(r)}_{\\omega_r,\\alpha_{r-1}\\alpha_r} \\delta_{\\omega_r,\\omega_r'}\n",
    "   $$\n",
    "4. Prime external indices of $\\Chi^0$ once\n",
    "   $$\n",
    "       {\\Chi^0}_{\\nu\\omega}^{\\nu'\\omega'} \\longrightarrow {\\Chi^0}_{\\nu'\\omega'}^{\\nu''\\omega''}\n",
    "   $$\n",
    "   and those of $\\Gamma$ twice\n",
    "   $$\n",
    "       {\\Gamma}_{\\nu\\omega}^{\\nu'\\omega'} \\longrightarrow {\\Gamma}_{\\nu''\\omega''}^{\\nu'''\\omega'''}.\n",
    "   $$\n",
    "5. Convert back into `ProjContainer{ProjTensorTrain}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "function makevertsdiagonal(patchesfuncs, sites)\n",
    "    (; full_patches, chi0_patches, gamma_patches) = patchesfuncs\n",
    "    (; sitesν, sitesν´, sitesω, sitesfused) = sites\n",
    "\n",
    "    full_mps = TCIA.ProjMPSContainer(Float64, full_patches, sitesfused)\n",
    "    chi0_mps = TCIA.ProjMPSContainer(Float64, chi0_patches, sitesfused)\n",
    "    gamma_mps = TCIA.ProjMPSContainer(Float64, gamma_patches, sitesfused)\n",
    "\n",
    "    sitesνν´_vec = [[ν, ν´] for (ν, ν´) in zip(sitesν, sitesν´)]\n",
    "    sitesω_vec = [[ω] for ω in sitesω]\n",
    "    sites_separateω = [x for pair in zip(sitesνν´_vec, sitesω_vec) for x in pair]\n",
    "    full_νν´_ω = Quantics.rearrange_siteinds(full_mps, sites_separateω)\n",
    "    chi0_νν´_ω = Quantics.rearrange_siteinds(chi0_mps, sites_separateω)\n",
    "    gamma_νν´_ω = Quantics.rearrange_siteinds(gamma_mps, sites_separateω)\n",
    "\n",
    "    full_νν´_ωω´ = Quantics.makesitediagonal(full_νν´_ω, \"ω\")\n",
    "    chi0_νν´_ωω´ = Quantics.makesitediagonal(chi0_νν´_ω, \"ω\")\n",
    "    gamma_νν´_ωω´ = Quantics.makesitediagonal(gamma_νν´_ω, \"ω\")\n",
    "    diagonal_sites = full_νν´_ωω´.sites\n",
    "\n",
    "    chi0_νν´_ω´ω´´ = prime(chi0_νν´_ωω´)\n",
    "    gamma_νν´_ω´´ω´´´ = prime(gamma_νν´_ωω´, 2)\n",
    "\n",
    "    full_ptt = TCIA.ProjTTContainer{Float64}(full_νν´_ωω´)\n",
    "    chi0_ptt = TCIA.ProjTTContainer{Float64}(chi0_νν´_ω´ω´´)\n",
    "    gamma_ptt = TCIA.ProjTTContainer{Float64}(gamma_νν´_ω´´ω´´´)\n",
    "\n",
    "    pttfuncs = (; full_ptt, chi0_ptt, gamma_ptt)\n",
    "\n",
    "    return pttfuncs, diagonal_sites\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are now ready to compute the BSE\n",
    "$$\n",
    "    \\Phi_{\\nu\\omega}^{\\nu'''\\omega'''} = \\sum_{\\nu'\\omega'} F_{\\nu\\omega}^{\\nu'\\omega'} \\left(\\sum_{\\nu''\\omega''} {\\Chi^0}_{\\nu'\\omega'}^{\\nu''\\omega''} \\Gamma_{\\nu''\\omega''}^{\\nu'''\\omega'''} \\right)\n",
    "$$\n",
    "by two applications of `adaptivematmul`, which — like `adaptiveinterpolate` — creates patches as necessary to ensure no bond dimension exceeds $D_\\mathrm{max}$.\n",
    "To remove the superfluous $\\omega'''$ index, we again go through `ProjMPSContainer`.\n",
    "First, the diagonals are extracted from the $\\omega\\omega'$-tensors, and then merged into the $\\nu\\nu'$-tensors.\n",
    "The result is then converted back to `ProjContainer{ProjTensorTrain}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calculatebse(pttfuncs, diagonal_sites, maxbonddim, sites)\n",
    "    (; full_ptt, chi0_ptt, gamma_ptt) = pttfuncs\n",
    "    pordering = TCIA.PatchOrdering(collect(eachindex(diagonal_sites)))\n",
    "\n",
    "    chi0_gamma_ptt = TCIA.adaptivematmul(chi0_ptt, gamma_ptt, pordering; maxbonddim)\n",
    "    phi_bse_diagonal = TCIA.adaptivematmul(full_ptt, chi0_gamma_ptt, pordering; maxbonddim)\n",
    "\n",
    "    phi_bse_diagonal_projmps = TCIA.ProjMPSContainer(Float64, phi_bse_diagonal, diagonal_sites)\n",
    "    phi_bse_projmps_νν´_ω = Quantics.extractdiagonal(phi_bse_diagonal_projmps, \"ω\")\n",
    "    phi_bse_projmps_νν´ω = Quantics.rearrange_siteinds(phi_bse_projmps_νν´_ω, sites.sitesfused)\n",
    "    phi_bse = TCIA.ProjTTContainer{Float64}(phi_bse_projmps_νν´ω)\n",
    "\n",
    "    return phi_bse\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "To test our implementation, we compare it against straightforward summation.\n",
    "As error measure, we choose the relative maximum norm over the frequency box\n",
    "$$\n",
    "    \\mathrm{Error} = \\frac{\\lVert\\Phi_{\\nu\\nu'\\omega} - \\Phi^{\\mathrm{ref}}_{\\nu\\nu'\\omega} \\rVert_\\infty}{\\lVert \\Phi^{\\mathrm{ref}}_{\\nu\\nu'\\omega}\\rVert_\\infty}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "function comparereference(phi_bse, plainfuncs, grid)\n",
    "    N = 2^(grid.R)\n",
    "    νν = range(-N + 1; step=2, length=N)\n",
    "    ν´ν´ = range(-N + 1; step=2, length=N)\n",
    "    ωω = range(-N; step=2, length=N)\n",
    "    box = [(ν, ν´, ω) for ν in νν, ν´ in ν´ν´, ω in ωω]\n",
    "\n",
    "    (; fq_full, fq_chi0, fq_gamma) = plainfuncs\n",
    "    phi_normalmul = [sum(fq_full(ν, ν´´, ω) * fq_chi0(ν´´, ν´´´, ω) * fq_gamma(ν´´´, ν´, ω) for ν´´ in νν, ν´´´ in νν) for (ν, ν´, ω) in box]\n",
    "\n",
    "    phi_adaptivemul = [phi_bse(QG.origcoord_to_quantics(grid, p)) for p in box]\n",
    "\n",
    "    error = norm(phi_normalmul - phi_adaptivemul, Inf) / norm(phi_normalmul, Inf)\n",
    "    return error\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "function main(U, beta, ch, R, maxbonddim)\n",
    "    grid, sites = setup(R)\n",
    "    plainfuncs, quanticsfuncs = makeverts(U, beta, ch, grid)\n",
    "    patchesfuncs = interpolateverts(quanticsfuncs, grid, maxbonddim, sites)\n",
    "    pttfuncs, diagonal_sites = makevertsdiagonal(patchesfuncs, sites)\n",
    "    phi_bse = calculatebse(pttfuncs, diagonal_sites, maxbonddim, sites)\n",
    "    error = comparereference(phi_bse, plainfuncs, grid)\n",
    "    return error\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform the comparison in all four frequency channels at $U = 3$, $\\beta = 10$ with $R = 4$ (so $(2^4)^3 = 4096$ frequency points) and $D_\\mathrm{max} = 40$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DensityChannel():\t2.936004435027869e-14\n",
      "MagneticChannel():\t1.080409120821319e-14\n",
      "SingletChannel():\t2.362578783304851e-14\n",
      "TripletChannel():\t2.384282932831692e-15\n"
     ]
    }
   ],
   "source": [
    "ch_d = DensityChannel()\n",
    "ch_m = MagneticChannel()\n",
    "ch_s = SingletChannel()\n",
    "ch_t = TripletChannel()\n",
    "channels = (ch_d, ch_m, ch_s, ch_t)\n",
    "\n",
    "for ch in channels\n",
    "    error = main(3.0, 10.0, ch, 4, 40)\n",
    "    println(ch, \":\\t\", error)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So results from our implementation are up to floating point accuracy identical to the reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CairoMakie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.0",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
